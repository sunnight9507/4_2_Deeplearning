{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 : Collaborative Filtering for Implicit Feedback Datasets - Yifan Hu\n",
    "\n",
    "http://yifanhu.net/PUB/cf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화 300개 자료 저장\n",
    "# User 수는 1000명\n",
    "data = {}\n",
    "movie_id = 0\n",
    "user_name = 0\n",
    "rating = 0\n",
    "user_list = []\n",
    "\n",
    "\n",
    "with open('combined_data_1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if(line.find(\":\") != -1):\n",
    "            continue\n",
    "        line_split = line.split(',')\n",
    "        user_name = int(line_split[0])\n",
    "        if user_name in user_list:\n",
    "            continue\n",
    "        else:\n",
    "            user_list.append(user_name)\n",
    "        if len(user_list) > 1000:\n",
    "            break\n",
    "\n",
    "with open('combined_data_1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if(line.find(\":\") != -1):\n",
    "            movie_id = int(line.replace(\":\",\"\")) - 1\n",
    "            if(movie_id >= 300): break\n",
    "            data[movie_id] = {}\n",
    "        else:\n",
    "            line_split = line.split(',')\n",
    "            user_name = int(line_split[0])\n",
    "            rating = int(line_split[1])\n",
    "            if user_name in user_list:\n",
    "                data[movie_id][user_name] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Feedback data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 4., ..., 0., 1., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 3., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 3., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = np.nan_to_num(np.array(pd.DataFrame(data)))\n",
    "\n",
    "Matrix"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선호도 행렬 P\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Raiting 값이 존재하면 1 / 존재하지 않으면 0으로 초기화\n",
    "P = np.copy(Matrix)\n",
    "P[P > 0] = 1\n",
    "print(P)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신뢰도 행렬 C\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201.   1.   1. ...   1.   1.   1.]\n",
      " [  1.   1. 161. ...   1.  41.   1.]\n",
      " [121.   1.   1. ...   1.   1.   1.]\n",
      " ...\n",
      " [  1.   1. 121. ...   1.   1.   1.]\n",
      " [161.   1.   1. ...   1.   1.   1.]\n",
      " [  1. 121.   1. ...   1.   1.   1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alpha = 40 으로 초기화(위 논문에서 좋은 결과가 나온 값)\n",
    "C = 1 + 40 * Matrix\n",
    "print(C)\n",
    "print()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(C, P, xTy, lambda_, X, Y):\n",
    "    predict_error = np.sum(C * np.square(P - xTy))\n",
    "    return predict_error, predict_error + lambda_ * (np.sum(np.square(X)) + np.sum(np.square(Y)))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize user factors\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize item factors\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, C, P, num_of_user, num_of_item, dimension, lambda_):\n",
    "    # user\n",
    "    yT = np.transpose(Y)\n",
    "    D = np.dot(lambda_, np.identity(dimension)) # lambda * identity_matirix\n",
    "    for u in range(num_of_user):\n",
    "        yT_Cu_y_D_inverse = np.linalg.inv(np.dot(np.dot(yT, np.diag(C[u])), Y) + D) # (yTCuY + D)의 역행렬\n",
    "        yT_Cu_pu = np.dot(np.dot(yT, np.diag(C[u])), P[u])\n",
    "        X[u] = np.dot(yT_Cu_y_D_inverse, yT_Cu_pu)\n",
    "    \n",
    "    # item\n",
    "    xT = np.transpose(X)\n",
    "    for i in range(num_of_item):\n",
    "        xT_Ci_x_D_inverse = np.linalg.inv(np.dot(np.dot(xT, np.diag(C[:, i])), X) + D) # (xT_Ci_x + D)의 역행렬\n",
    "        xT_Ci_pi = np.dot(np.dot(xT, np.diag(C[:, i])), P[:, i])\n",
    "        Y[i] = np.dot(xT_Ci_x_D_inverse, xT_Ci_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda : 10, dimension : 10 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "---step 10---\n",
      "total loss: 52135.558131\n",
      "predict_error: 38799.372578\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "total loss: 60025.177800\n",
      "predict_error: 39758.280471\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 29796.383037\n",
      "predict_error: 10591.767195\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 43524.086629\n",
      "predict_error: 12875.169004\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 25357.717392\n",
      "predict_error: 4732.664474\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 41202.284023\n",
      "predict_error: 8016.520529\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 23544.471101\n",
      "predict_error: 3123.766140\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 41497.468734\n",
      "predict_error: 7326.472457\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23596.815773\n",
      "predict_error: 2922.842906\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 41340.967976\n",
      "predict_error: 7178.566355\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23281.268019\n",
      "predict_error: 2853.844995\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 41130.352140\n",
      "predict_error: 7112.203665\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23094.108826\n",
      "predict_error: 2824.157611\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 41719.838644\n",
      "predict_error: 7016.705931\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23018.038115\n",
      "predict_error: 2806.439249\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 41350.856356\n",
      "predict_error: 6979.927249\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23000.573868\n",
      "predict_error: 2795.034611\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 41315.917010\n",
      "predict_error: 6940.386198\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23061.325248\n",
      "predict_error: 2782.083810\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 42173.877894\n",
      "predict_error: 6837.740264\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "total loss: 61796.133500\n",
      "predict_error: 46428.991479\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "---step 10---\n",
      "total loss: 74277.997365\n",
      "predict_error: 47437.035841\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 30208.121002\n",
      "predict_error: 11304.967045\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "total loss: 47704.234261\n",
      "predict_error: 12679.384965\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 24777.999383\n",
      "predict_error: 4821.840262\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 44666.651401\n",
      "predict_error: 7101.962525\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23900.061989\n",
      "predict_error: 3252.973859\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 43296.640056\n",
      "predict_error: 6114.121015\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23814.800362\n",
      "predict_error: 2824.193744\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43347.180269\n",
      "predict_error: 5941.438407\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24184.813026\n",
      "predict_error: 2721.485529\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42749.505426\n",
      "predict_error: 5909.775767\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24518.374621\n",
      "predict_error: 2697.062539\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42420.744740\n",
      "predict_error: 5880.637139\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25106.358974\n",
      "predict_error: 2679.003750\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42187.489203\n",
      "predict_error: 5862.559344\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25588.757197\n",
      "predict_error: 2632.531531\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42186.738210\n",
      "predict_error: 5843.848338\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26018.730332\n",
      "predict_error: 2629.295689\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42206.373756\n",
      "predict_error: 5844.219900\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "total loss: 64685.286944\n",
      "predict_error: 50529.364800\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "---step 10---\n",
      "total loss: 82161.206824\n",
      "predict_error: 51739.972693\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 30522.828044\n",
      "predict_error: 11966.985011\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "total loss: 49327.509264\n",
      "predict_error: 12960.818833\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 25140.121904\n",
      "predict_error: 5070.488314\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 44954.209865\n",
      "predict_error: 6964.525212\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24987.767841\n",
      "predict_error: 3331.989395\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43320.652875\n",
      "predict_error: 5938.220838\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25106.830071\n",
      "predict_error: 2810.096282\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 30\n",
      "\n",
      "---step 1---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42933.725252\n",
      "predict_error: 5702.411120\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26108.937830\n",
      "predict_error: 2689.853526\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42846.806920\n",
      "predict_error: 5654.724959\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26797.912786\n",
      "predict_error: 2677.047250\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43019.391230\n",
      "predict_error: 5609.818838\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 27498.060404\n",
      "predict_error: 2689.185916\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43687.668680\n",
      "predict_error: 5536.852028\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28235.242496\n",
      "predict_error: 2645.298668\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44138.722558\n",
      "predict_error: 5494.447721\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28754.473365\n",
      "predict_error: 2673.798834\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44880.938810\n",
      "predict_error: 5422.801258\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "total loss: 67130.545511\n",
      "predict_error: 53327.980468\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "---step 10---\n",
      "total loss: 85034.101738\n",
      "predict_error: 54465.971449\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 31798.679569\n",
      "predict_error: 12630.375312\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 49553.944982\n",
      "predict_error: 13467.552335\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 26415.337061\n",
      "predict_error: 5323.747333\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 44250.780404\n",
      "predict_error: 6984.020840\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 26002.169989\n",
      "predict_error: 3130.261261\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43340.722039\n",
      "predict_error: 5898.163908\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26565.769175\n",
      "predict_error: 2818.928899\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43499.584654\n",
      "predict_error: 5609.354491\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 27932.169043\n",
      "predict_error: 2708.051022\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44041.041580\n",
      "predict_error: 5513.741010\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28829.616693\n",
      "predict_error: 2702.773742\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44770.782661\n",
      "predict_error: 5445.366443\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 29414.077905\n",
      "predict_error: 2742.949253\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 46311.829960\n",
      "predict_error: 5337.523534\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 30123.111913\n",
      "predict_error: 2735.923469\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 46610.544786\n",
      "predict_error: 5216.078020\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 30750.956218\n",
      "predict_error: 2771.982261\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 47917.946570\n",
      "predict_error: 5124.451213\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 파라미터별 total_loss\n",
    "result = []\n",
    "\n",
    "# 정규화에 필요한 lambda\n",
    "lambda_ = [i for i in range(10,30,10)]\n",
    "\n",
    "# Latent Factor 행렬의 차원\n",
    "dimension = [i for i in range(10,410,40)]\n",
    "\n",
    "# Latent Factor 행렬의 차원\n",
    "alpha_ = [i for i in range(10,50,10)]\n",
    "\n",
    "# user, item 수 \n",
    "num_of_user, num_of_item = Matrix.shape[0], Matrix.shape[1]\n",
    "\n",
    "for a in alpha_:\n",
    "    for d in dimension:\n",
    "        for l in lambda_:\n",
    "            # Latent Factor Matrix 초기 랜덤값 생성\n",
    "            # X : 유저\n",
    "            # Y : 영화\n",
    "            np.random.seed(100)\n",
    "            X = np.random.rand(num_of_user, d) * 0.01\n",
    "            Y = np.random.rand(num_of_item, d) * 0.01\n",
    "\n",
    "            C = 1 + a * Matrix\n",
    "            temp_losses = 10000000\n",
    "            temp_predict_error = 10000000\n",
    "\n",
    "            print('lambda : %d, dimension : %d alpha : %d' %(l,d,a))\n",
    "            print()\n",
    "            i = 0\n",
    "            while(True):\n",
    "                i += 1\n",
    "                print('---step %d---' % i)\n",
    "                if i!=0:    \n",
    "                    optimize(X, Y, C, P, num_of_user, num_of_item, d, l)\n",
    "                    predict = np.dot(X, np.transpose(Y))\n",
    "                    predict_error, total_loss = loss_function(C, P, predict,l,X,Y)\n",
    "\n",
    "                    if temp_predict_error < predict_error:\n",
    "                        break                \n",
    "                    if temp_losses - total_loss < 1000 or i == 10:\n",
    "                        break\n",
    "\n",
    "                temp_predict_error = predict_error\n",
    "                temp_losses = total_loss\n",
    "\n",
    "            print(\"total loss: %f\" % total_loss)\n",
    "            print(\"predict_error: %f\" % predict_error)\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            result.append([d,l,a,predict_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>370</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2629.295689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>330</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2632.531531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>330</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2645.298668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>370</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2673.798834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2677.047250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>290</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2679.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>290</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2689.185916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2689.853526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2697.062539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2702.773742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2708.051022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2721.485529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>330</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2735.923469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>290</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2742.949253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>370</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2771.982261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>370</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2782.083810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>330</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2795.034611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>290</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2806.439249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2810.096282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>2818.928899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2824.157611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>2824.193744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2853.844995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2922.842906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3123.766140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>3130.261261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3252.973859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>3331.989395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4732.664474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>4821.840262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>5938.220838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>170</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5941.438407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>6114.121015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>370</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6837.740264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>330</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6940.386198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>6964.525212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>290</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6979.927249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>6984.020840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>7016.705931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7101.962525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>210</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>7112.203665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>7178.566355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>7326.472457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>8016.520529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10591.767195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>11304.967045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11966.985011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>12630.375312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>12679.384965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>12875.169004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>12960.818833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>13467.552335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>38799.372578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>39758.280471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>46428.991479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>47437.035841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>50529.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>51739.972693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>53327.980468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>54465.971449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2             3\n",
       "38  370  10  20   2629.295689\n",
       "36  330  10  20   2632.531531\n",
       "56  330  10  30   2645.298668\n",
       "58  370  10  30   2673.798834\n",
       "52  250  10  30   2677.047250\n",
       "34  290  10  20   2679.003750\n",
       "54  290  10  30   2689.185916\n",
       "50  210  10  30   2689.853526\n",
       "32  250  10  20   2697.062539\n",
       "72  250  10  40   2702.773742\n",
       "70  210  10  40   2708.051022\n",
       "30  210  10  20   2721.485529\n",
       "76  330  10  40   2735.923469\n",
       "74  290  10  40   2742.949253\n",
       "78  370  10  40   2771.982261\n",
       "18  370  10  10   2782.083810\n",
       "16  330  10  10   2795.034611\n",
       "14  290  10  10   2806.439249\n",
       "48  170  10  30   2810.096282\n",
       "68  170  10  40   2818.928899\n",
       "12  250  10  10   2824.157611\n",
       "28  170  10  20   2824.193744\n",
       "10  210  10  10   2853.844995\n",
       "8   170  10  10   2922.842906\n",
       "6   130  10  10   3123.766140\n",
       "66  130  10  40   3130.261261\n",
       "26  130  10  20   3252.973859\n",
       "46  130  10  30   3331.989395\n",
       "4    90  10  10   4732.664474\n",
       "24   90  10  20   4821.840262\n",
       "..  ...  ..  ..           ...\n",
       "47  130  20  30   5938.220838\n",
       "29  170  20  20   5941.438407\n",
       "27  130  20  20   6114.121015\n",
       "19  370  20  10   6837.740264\n",
       "17  330  20  10   6940.386198\n",
       "45   90  20  30   6964.525212\n",
       "15  290  20  10   6979.927249\n",
       "65   90  20  40   6984.020840\n",
       "13  250  20  10   7016.705931\n",
       "25   90  20  20   7101.962525\n",
       "11  210  20  10   7112.203665\n",
       "9   170  20  10   7178.566355\n",
       "7   130  20  10   7326.472457\n",
       "5    90  20  10   8016.520529\n",
       "2    50  10  10  10591.767195\n",
       "22   50  10  20  11304.967045\n",
       "42   50  10  30  11966.985011\n",
       "62   50  10  40  12630.375312\n",
       "23   50  20  20  12679.384965\n",
       "3    50  20  10  12875.169004\n",
       "43   50  20  30  12960.818833\n",
       "63   50  20  40  13467.552335\n",
       "0    10  10  10  38799.372578\n",
       "1    10  20  10  39758.280471\n",
       "20   10  10  20  46428.991479\n",
       "21   10  20  20  47437.035841\n",
       "40   10  10  30  50529.364800\n",
       "41   10  20  30  51739.972693\n",
       "60   10  10  40  53327.980468\n",
       "61   10  20  40  54465.971449\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result).sort_values(by = [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 이상적인 초기값\n",
    "    - dimension = 370\n",
    "    - lambda_ = 10\n",
    "    - alpha = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda : 20, dimension : 370\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42206.373756\n",
      "predict_error: 5844.219900\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정규화에 필요한 lambda\n",
    "lambda_ = 10\n",
    "\n",
    "# Latent Factor 행렬의 차원\n",
    "dimension = 370\n",
    "\n",
    "alpha = 20\n",
    "\n",
    "# user, item 수 \n",
    "num_of_user, num_of_item = Matrix.shape[0], Matrix.shape[1]\n",
    "\n",
    "# Latent Factor Matrix 초기 랜덤값 생성\n",
    "# X : 유저\n",
    "# Y : 영화\n",
    "np.random.seed(100)\n",
    "X = np.random.rand(num_of_user, d) * 0.01\n",
    "Y = np.random.rand(num_of_item, d) * 0.01\n",
    "\n",
    "C = 1 + alpha * Matrix\n",
    "temp_losses = 10000000\n",
    "temp_predict_error = 10000000\n",
    "\n",
    "print('lambda : %d, dimension : %d' %(l,d))\n",
    "print()\n",
    "i = 0\n",
    "while(True):\n",
    "    i += 1\n",
    "    print('---step %d---' % i)\n",
    "    if i!=0:    \n",
    "        optimize(X, Y, C, P, num_of_user, num_of_item, d, l)\n",
    "        predict = np.dot(X, np.transpose(Y))\n",
    "        predict_error, total_loss = loss_function(C, P, predict,l,X,Y)\n",
    "\n",
    "        if temp_predict_error < predict_error:\n",
    "            break                \n",
    "        if temp_losses - total_loss < 1000 or i == 10:\n",
    "            break\n",
    "\n",
    "    temp_predict_error = predict_error\n",
    "    temp_losses = total_loss\n",
    "\n",
    "print(\"total loss: %f\" % total_loss)\n",
    "print(\"predict_error: %f\" % predict_error)\n",
    "print()\n",
    "print()\n",
    "\n",
    "result_matrix = np.dot(X, np.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98634405, -0.13158723, -0.11921972, ...,  0.06416346,\n",
       "         0.13612756, -0.01116031],\n",
       "       [ 0.58100977,  0.16981198,  0.99403672, ...,  0.20149689,\n",
       "         1.00151224,  0.02854591],\n",
       "       [ 0.99094368,  0.14467849,  0.02114363, ...,  0.05546217,\n",
       "         0.18029056,  0.00808861],\n",
       "       ...,\n",
       "       [ 0.09246973,  0.1532611 ,  0.98209636, ..., -0.00353585,\n",
       "         0.54894716, -0.0110194 ],\n",
       "       [ 0.99158125,  0.20247106,  0.25385307, ...,  0.02405924,\n",
       "         0.37860486, -0.05152268],\n",
       "       [ 0.20516819,  0.95516217,  0.1336867 , ...,  0.0425397 ,\n",
       "         0.28857319,  0.00856342]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
